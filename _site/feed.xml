<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Matt Giguere</title>
    <description>Hi, I&#39;m Matt Giguere, a graduate student searching for rocky planets and characterizing stellar activity of the stars that host them. In addition to working towards the discovery  of other rocky worlds, I am constantly working to defend my best dad  of the year title. I also enjoy learning new programming languages,  new statistical methods, and new visualization tools, and making  things in many different media.
</description>
    <link>http://mattgiguere.github.io/</link>
    <atom:link href="http://mattgiguere.github.io/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Thu, 12 Mar 2015 11:01:04 -0400</pubDate>
    <lastBuildDate>Thu, 12 Mar 2015 11:01:04 -0400</lastBuildDate>
    <generator>Jekyll v2.5.3</generator>
    
      <item>
        <title>Running MPI Python Code on Yale Omega</title>
        <description>&lt;p&gt;Yesterday I got my Parallel Tempering MCMC code working on Yale’s
&lt;a href=&quot;http://westcampus.yale.edu/research/science-medicine-engineering/core-facililties/high-performance-computing-center&quot;&gt;Omega Cluster&lt;/a&gt;. I found &lt;a href=&quot;https://hpc.research.yale.edu/hpc_user_wiki/index.php/Omega&quot;&gt;the “documentation”&lt;/a&gt; to be far
out of date, and not very helpful. Fortunately, there were several people in
the department that could help me out (thanks Kaylea, Duncan, and Andys!!). In
the hopes of easing the reducing the setup time for others that may be
interested in using Omega for their research, I decided to write this blog post
detailing my setup.&lt;/p&gt;

&lt;h3 id=&quot;welcome-email&quot;&gt;Welcome Email&lt;/h3&gt;

&lt;p&gt;When your account is first created, you will receive an email that starts off
like this:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Welcome to Omega - Yale High Performance Cluster&lt;/p&gt;

  &lt;p&gt;An account has been created for you on omega.hpc.yale.edu.&lt;/p&gt;

  &lt;p&gt;Details about the cluster and its usage can be found at
* http://hpc.research.yale.edu/wiki/index.php/Omega&lt;/p&gt;

  &lt;p&gt;Before you can login you will need to create and upload your ssh key here:
* http://gold.hpc.yale.internal/cgi-bin/sshkeys.py&lt;/p&gt;

  &lt;p&gt;For additional information about ssh please visit:
* http://hpc.yale.edu/faq/secure-shell-faq/&lt;/p&gt;

  &lt;p&gt;There are several queues to choose from, each serving a different purpose
* http://hpc.research.yale.edu/wiki/index.php/Omega#FAS_Queues&lt;/p&gt;

  &lt;p&gt;When submitting jobs, some of the qsub terms have changed; most
importantly when selecting the number of nodes or number of
processors:
* http://hpc.research.yale.edu/wiki/index.php/Omega#Scheduling_your_Programs_to_run&lt;/p&gt;

&lt;/blockquote&gt;

&lt;h4 id=&quot;ssh-keys&quot;&gt;SSH Keys&lt;/h4&gt;
&lt;p&gt;The first thing to note that is not mentioned in the welcome email message (and
I could not find mentioned in the online documentation) is that the link given
to upload your SSH key does not work in the Safari browser. Use Google Chrome.&lt;/p&gt;

&lt;h4 id=&quot;sshing-into-omega&quot;&gt;SSHing Into Omega&lt;/h4&gt;
&lt;p&gt;Next, to SSH into omega, I used the command:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sh&quot; data-lang=&quot;sh&quot;&gt;ssh -p22 -i ~/.ssh/myomegakey netid@omega.hpc.yale.edu&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h4 id=&quot;creating-a-test-script&quot;&gt;Creating a Test Script&lt;/h4&gt;
&lt;p&gt;Now comes the fun stuff. All jobs submitted for processing need to be wrapped
in a shell script. Before you do anything else, create a test script and see
if it works. The sample script on the HPC site is out of date and results in
error messages. Here’s a sample script that works (as of March 12, 2015):&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sh&quot; data-lang=&quot;sh&quot;&gt;&lt;span class=&quot;c&quot;&gt;#!/bin/bash&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;###fas_devel: for compiling and testing code,&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;###restricted to one job per user32 max cores, 4 hours max walltime&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;###name of job&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#PBS -N mytestjob&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;###-q queue_name&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#PBS -q fas_devel&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;###PBS -l procs=1, tpn=1&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#PBS -l nodes=1:ppn=8,mem=35gb&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;#PBS -l walltime=4:00:00&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;##oe: stdout(o) and stderr(e)&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#PBS -j oe&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;##where to put the output&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#PBS -o output_dir/$PBS_JOBNAME.$PBS_JOBID&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;##what you get emails for ((a)borted, (b)egin, (e)nd)&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#PBS -m abe&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;###email yourself status messages about your job:&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#PBS -M firstname.lastname@yale.edu&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;##Import terminal env variables&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#PBS -V&lt;/span&gt;

&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;OMP_NUM_THREADS&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;8

&lt;span class=&quot;c&quot;&gt;###run from directory the job is submitted from&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$PBS_O_WORKDIR&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;##Command to execute:&lt;/span&gt;
date&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

</description>
        <pubDate>Thu, 12 Mar 2015 06:06:07 -0400</pubDate>
        <link>http://mattgiguere.github.io/2015/03/12/running-mpi-python-code-on-yale-omega.html</link>
        <guid isPermaLink="true">http://mattgiguere.github.io/2015/03/12/running-mpi-python-code-on-yale-omega.html</guid>
        
        <category>python,</category>
        
        <category>mpi4py,</category>
        
        <category>mcmc,</category>
        
        <category>omega,</category>
        
        <category>yale,</category>
        
        <category>hpc</category>
        
        
      </item>
    
      <item>
        <title>Creating an AWS EC2 Cluster</title>
        <description>&lt;p&gt;Today I decided to scale up my MPI MCMC sampling to use more nodes.In a
&lt;a href=&quot;/2015/01/27/setting-up-mpi4py.html&quot;&gt;previous blog post&lt;/a&gt;, I showed how I installed MPI on our cluster. I
got it up to 96 cores, but I scaled back and was using about 50 cores from our
cluster for my analysis. I could add more, but there is currently a lot of
demand for CPUs in our research group. Instead,
I’m going try out Amazon Web Services (AWS) Elastic Cloud Computing (EC2) for
this project.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/2015/03/10/scaling-up-with-aws.html&quot;&gt;Yesterday&lt;/a&gt; I setup an AWS account and created an Amazon Machine
Instance (AMI). Today, I’m going to create the cluster. I found
&lt;a href=&quot;http://cs.smith.edu/dftwiki/index.php/Tutorial:_Create_an_MPI_Cluster_on_the_Amazon_Elastic_Cloud_(EC2)&quot;&gt;this post&lt;/a&gt; to be helpful.&lt;/p&gt;

&lt;p&gt;First, I installed &lt;a href=&quot;http://star.mit.edu/cluster/docs/latest/installation.html&quot;&gt;StarCluster&lt;/a&gt;, a python package made
specifically for creating and managing AWS EC2 distributed computing clusters.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sh&quot; data-lang=&quot;sh&quot;&gt;pip install StarCluster&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;I then opened a new Terminal window and followed the StarCluster
&lt;a href=&quot;http://star.mit.edu/cluster/docs/latest/quickstart.html&quot;&gt;Quick start&lt;/a&gt; guide. The first thing is to create a config
file:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sh&quot; data-lang=&quot;sh&quot;&gt;∞ starcluster &lt;span class=&quot;nb&quot;&gt;help&lt;/span&gt;
StarCluster - &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;http://star.mit.edu/cluster&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;v. 0.95.6&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
Software Tools &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; Academics and Researchers &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;STAR&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
Please submit bug reports to starcluster@mit.edu

!!! ERROR - config file /home/matt/.starcluster/config does not exist

Options:
--------
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;1&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; Show the StarCluster config template
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;2&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; Write config template to /home/matt/.starcluster/config
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;q&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; Quit

Please enter your selection: 2

&amp;gt;&amp;gt;&amp;gt; Config template written to /home/matt/.starcluster/config
&amp;gt;&amp;gt;&amp;gt; Please customize the config template
∞ &lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; .starcluster/
∞ emacs config&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Modifying the configuration file to use my AWS_ACCESS_KEY_ID and
AWS_SECRET_ACCESS_KEY was a bit tricky. Amazon changed the way it manages
access keys and no longer allows them to be created at the root level. The
&lt;a href=&quot;http://docs.aws.amazon.com/IAM/latest/UserGuide/Using_SettingUpUser.html&quot;&gt;AWS IAM User documentation&lt;/a&gt; describes how to create a user and
grab their access key. In a nutshell, do this:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;go to: https://console.aws.amazon.com/iam/&lt;/li&gt;
  &lt;li&gt;In the left-hand navigation page
    &lt;ul&gt;
      &lt;li&gt;click &lt;strong&gt;Users&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;click the blue &lt;strong&gt;Create New Users&lt;/strong&gt; button at the top&lt;/li&gt;
      &lt;li&gt;enter a username in the field&lt;/li&gt;
      &lt;li&gt;click the blue &lt;strong&gt;Create&lt;/strong&gt; button at the bottom of the screen&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Your new access key and secret keys should then appear on the screen. Copy
these into your .starcluster/config file. For the account number, use your
Account Id, which can be found at the top of &lt;a href=&quot;https://console.aws.amazon.com/billing/home#/account&quot;&gt;“Account Settings”&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Scroll down a bit and modify the &lt;code&gt;KEY_LOCATION&lt;/code&gt; to point to the SSH Key you use
to connect to AWS (you had to create a key pair when you created an AWS
  account).&lt;/p&gt;

</description>
        <pubDate>Wed, 11 Mar 2015 09:58:53 -0400</pubDate>
        <link>http://mattgiguere.github.io/2015/03/11/creating-an-aws-ec2-cluster.html</link>
        <guid isPermaLink="true">http://mattgiguere.github.io/2015/03/11/creating-an-aws-ec2-cluster.html</guid>
        
        <category>python,</category>
        
        <category>mpi4py,</category>
        
        <category>mcmc,</category>
        
        <category>aws,</category>
        
        <category>amazon,</category>
        
        <category>ec2</category>
        
        
      </item>
    
      <item>
        <title>Scaling Up With AWS</title>
        <description>&lt;p&gt;As mentioned in a &lt;a href=&quot;/2015/03/09/parallel-tempering.html&quot;&gt;previous blog post&lt;/a&gt;, my parallel tempering code is
now working. There is still work to be done in adding new physics,
but I am now in a position to benefit from some extra computing
power. I’m going to try using &lt;a href=&quot;http://aws.amazon.com/ec2/&quot;&gt;Amazon EC2&lt;/a&gt; for this project.&lt;/p&gt;

&lt;p&gt;First, I launched an instance running the Amazon Linux AMI (HVM).
&lt;a href=&quot;http://badhessian.org/2013/11/cluster-computing-for-027hr-using-amazon-ec2-and-ipython-notebook/&quot;&gt;This blog post&lt;/a&gt; may be helpful in setting things up.&lt;/p&gt;

&lt;p&gt;Once the instance was created, and my keys were all setup, I SSHed into my
instance. My favorite distribution of scientific python is anaconda python.
This can be easily downloaded onto the AWS virtual machine instance by&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;going to the Anaconda downloads page&lt;/li&gt;
  &lt;li&gt;selecting the linux OS&lt;/li&gt;
  &lt;li&gt;right-clicking in the browser on the “Linux 64-Bit - Python 2.7” button&lt;/li&gt;
  &lt;li&gt;copying the link to the downloadable package&lt;/li&gt;
  &lt;li&gt;and pasting the link after &lt;code&gt;wget&lt;/code&gt; in the SSH session into the VMI.&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sh&quot; data-lang=&quot;sh&quot;&gt;ssh -p22 -i my-private-key ec2-user@my-public-ip
mkdir tempDownloads
&lt;span class=&quot;nb&quot;&gt;cd &lt;/span&gt;tempDownloads
wget http://09c8d0b2229f813c1b93-c95ac804525aac4b6dba79b00b39d1d3.r79.cf1.rackcdn.com/Anaconda-2.1.0-Linux-x86_64.sh&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Once the download has completed, installation is as simple as typing ls to
find out the name of the install script, running it, and following the
on-screen instructions.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sh&quot; data-lang=&quot;sh&quot;&gt;ls
-rw-rw-r-- &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt; ec2-user ec2-user &lt;span class=&quot;m&quot;&gt;353806962&lt;/span&gt; Sep &lt;span class=&quot;m&quot;&gt;30&lt;/span&gt; 19:37 Anaconda-2.1.0-Linux-x86_64.sh
bash Anaconda-2.1.0-Linux-x86_64.sh&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;If you said ‘yes’ at the end of installation to have the anaconda python path
appended to your .bashrc file, then starting anaconda python is as simple as
sourcing the changes to your .bashrc file and typing python:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sh&quot; data-lang=&quot;sh&quot;&gt;&lt;span class=&quot;nb&quot;&gt;source&lt;/span&gt; ~/.bashrc
python&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;There are a few packages I need to run my parallel tempering code. I’ll use
pip to install these:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sh&quot; data-lang=&quot;sh&quot;&gt;pip install emcee&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

</description>
        <pubDate>Tue, 10 Mar 2015 14:39:10 -0400</pubDate>
        <link>http://mattgiguere.github.io/2015/03/10/scaling-up-with-aws.html</link>
        <guid isPermaLink="true">http://mattgiguere.github.io/2015/03/10/scaling-up-with-aws.html</guid>
        
        <category>python,</category>
        
        <category>IPython,</category>
        
        <category>time</category>
        
        <category>series</category>
        
        <category>analysis,</category>
        
        <category>AWS,</category>
        
        <category>EC2</category>
        
        
      </item>
    
      <item>
        <title>Parallel Tempering</title>
        <description>&lt;p&gt;After a few days of working out the bugs in between other projects, I
now have the spot modeling code working with parallel tempering. Briefly,
&lt;a href=&quot;https://en.wikipedia.org/wiki/Parallel_tempering&quot;&gt;parallel tempering&lt;/a&gt; allows for better exploration of the
parameter space of multi-modal distributions. In my particular example, there
may be (and probably are) many spots on the surface of a star. I am trying to
find the most probable coordinates for the spots, as well as their sizes, and
other properties of the star. When performing the normal Affine Invariant MCMC
Ensemble sampling of &lt;a href=&quot;http://dan.iel.fm/emcee/current/&quot;&gt;emcee&lt;/a&gt;, Markov chains will get stuck in local
minima (e.g. smaller spot locations), and do not explore the full parameter
space to find the larger spot locations. Parallel tempering reduces the
height of the barriers between the posterior distribution, allowing chains
to fully explore the parameter space, and find the dominant spot locations.&lt;/p&gt;

&lt;p&gt;Here is the best fit solution employing a maximum likelihood method with an
excellent initial guess based on a grid search:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Show_TwoSpotModelLinearTrendCrat.png&quot; alt=&quot;Maximum Likelihood&quot; /&gt;&lt;/p&gt;

&lt;p&gt;And here are 100 random samples taken from the parallel tempering method:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Show_eeTwoSpotParTmp100Samps.png&quot; alt=&quot;Parallel Tempering&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Note the standard deviation of the residuals for the photometry is unchanged,
but the standard deviation of the residuals for the RV data benefited from
a 62 cm/s improvement.&lt;/p&gt;

</description>
        <pubDate>Mon, 09 Mar 2015 16:21:08 -0400</pubDate>
        <link>http://mattgiguere.github.io/2015/03/09/parallel-tempering.html</link>
        <guid isPermaLink="true">http://mattgiguere.github.io/2015/03/09/parallel-tempering.html</guid>
        
        <category>python,</category>
        
        <category>time</category>
        
        <category>series</category>
        
        <category>analysis,</category>
        
        <category>MPI,</category>
        
        <category>Bayesian,</category>
        
        <category>MCMC,</category>
        
        <category>Parallel</category>
        
        <category>Tempering</category>
        
        
      </item>
    
      <item>
        <title>The Last YastroML</title>
        <description>&lt;p&gt;Yesterday we concluded &lt;a href=&quot;https://github.com/YastroML/YastroML&quot;&gt;YastroML&lt;/a&gt;, the Yale astronomy Machine
Learning Discussion Group. Over the past year we have been irregularly meeting
to go over the newly released textbook &lt;a href=&quot;http://press.princeton.edu/titles/10159.html&quot;&gt;Statistics, Data Mining, and Machine
Learning in Astronomy&lt;/a&gt;: a textbook that, as its name implies, goes
over a variety of statistical, data mining, and machine learning techniques
that are relevant to astronomy. As I was looking into ordering the book, I
noticed on twitter that a group of people at Columbia and other institutions
in NYC had started up a discussion group to go over the material, which they
referred to as &lt;a href=&quot;https://github.com/adrn/NYCastroML&quot;&gt;NYCastroML&lt;/a&gt;. This sounded like a terrific idea, and
I immediately decided that I’d try to take part in this weeklyish events. I
started crafting an email to inform other people in the Yale astronomy
Department about the event, and my list of people to include grew, and grew,
and grew… I decided that instead I’d send an email out to the department
to gauge interest in organizing something here at Yale. The response was
overwhelming — &lt;a href=&quot;https://github.com/YastroML/YastroML&quot;&gt;YastroML&lt;/a&gt; was born.&lt;/p&gt;

&lt;p&gt;We started meeting weekly in March of the Spring 2014 semester; we stuck to our
weekly schedule fairly well until the end of the semester. Academics always
seem to think they will have plenty of free time come summer. In practice,
between conferences, workshops, summer schools, and extra curricular
activities, that never seems to be the case. With the end of the Spring
Semester came the end of our weekly schedule. We met sporadically since then,
and our meeting yesterday marked the completion of the final chapter.&lt;/p&gt;

&lt;p&gt;In this last meeting we covered time series analysis. Major topics included&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Discrete Fourier Transforms&lt;/li&gt;
  &lt;li&gt;Periodograms&lt;/li&gt;
  &lt;li&gt;Digital Filtering&lt;/li&gt;
  &lt;li&gt;Wavelets and Matched Filtering&lt;/li&gt;
  &lt;li&gt;Classification of periodic phenomena&lt;/li&gt;
  &lt;li&gt;Analysis of arrival time data&lt;/li&gt;
  &lt;li&gt;Analysis of Stochastic Processes&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I put together an &lt;a href=&quot;http://nbviewer.ipython.org/github/YastroML/YastroML/blob/master/Session19_150219/Ch10_TimeSeries.ipynb&quot;&gt;IPython notebook&lt;/a&gt; to lead the discussion. Having
dealt with time series analysis for the past several years while analyzing
RV measurements and light curves, I was comfortable with a lot of the material,
and added several examples and interactive components to the notebook to make
the session a little more pedagogical.&lt;/p&gt;

&lt;p&gt;Some of the highlights for me in this chapter were:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;seeing how easy it is to implement wavelets in python using &lt;a href=&quot;http://www.pybytes.com/pywavelets/&quot;&gt;PyWavelets&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;The use of truncated Fourier Series for searching for signals that may have
multiple reoccurring features, such as eclipsing binaries&lt;/li&gt;
  &lt;li&gt;The nonparametric Gregory-Loredo technique when dealing with sparse data sets&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Afterwards a few of us got together for a celebratory dram and to discuss how
the discussion group can be improved for the next time around.&lt;/p&gt;

</description>
        <pubDate>Fri, 20 Feb 2015 12:30:48 -0500</pubDate>
        <link>http://mattgiguere.github.io/2015/02/20/last-yastroml.html</link>
        <guid isPermaLink="true">http://mattgiguere.github.io/2015/02/20/last-yastroml.html</guid>
        
        <category>python,</category>
        
        <category>IPython</category>
        
        <category>notebook,</category>
        
        <category>time</category>
        
        <category>series</category>
        
        <category>analysis,</category>
        
        <category>YastroML</category>
        
        
      </item>
    
      <item>
        <title>More Spot Modeling</title>
        <description>&lt;p&gt;Continuing from where I &lt;a href=&quot;/2015/02/10/spot-modeling.html&quot;&gt;left off last time&lt;/a&gt;, I tested out a
three spot model today. Here’s the Maximum Likelihood solution
for the two spot model in two dimensions:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/TwoSpotModel.png&quot; alt=&quot;Two Spot Model&quot; /&gt;&lt;/p&gt;

&lt;p&gt;where I used an Aitoff projection to show the spot locations
and relative sizes. And here’s the three spot solution:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Show_ThreeSpotModel.png&quot; alt=&quot;Three Spot Model&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Note that the two rightmost spots in the three spot solution are very
similar in size to the rightmost spot in the two spot solution. And
the average latitude of those two rightmost spots in the three spot
solution is approximately the latitude of the single rightmost spot
in the two spot solution.&lt;/p&gt;

&lt;p&gt;Including only three spots and we already see the degenerate
dangers of spot modeling. On the two do list is to take a
bayesian approach and use the &lt;code&gt;emcee&lt;/code&gt; MCMC sampler to further
explore parameter space and make sure the two rightmost spots in
the two spot solution are not both getting caught in the same
local minimum.&lt;/p&gt;

&lt;p&gt;We also have a lot of prior information we know for this problem
that we’ll be able to include when taking the Bayesian approach.
More on that later…&lt;/p&gt;

</description>
        <pubDate>Thu, 12 Feb 2015 15:45:45 -0500</pubDate>
        <link>http://mattgiguere.github.io/2015/02/12/more-spot-modeling.html</link>
        <guid isPermaLink="true">http://mattgiguere.github.io/2015/02/12/more-spot-modeling.html</guid>
        
        <category>python,</category>
        
        <category>simulation,</category>
        
        <category>animation,</category>
        
        <category>pandas,</category>
        
        <category>map</category>
        
        <category>projections,</category>
        
        <category>aitoff</category>
        
        
      </item>
    
      <item>
        <title>Stellar Spot Modeling</title>
        <description>&lt;p&gt;Over the past two days I worked on fitting the simultaneous MOST photometry
and CHIRON RV measurements of Epsilon Eridani. This document describes
some of the more general code as well as the early results. The full
spot modeling code will be made publicly available when the peer-reviewed
paper is accepted.&lt;/p&gt;

&lt;h4 id=&quot;importing-the-data&quot;&gt;Importing the Data&lt;/h4&gt;

&lt;p&gt;After finding out over the weekend that the times we stored in IDL data
structures (and published over the last 6 years) were erroneous, I used
the exposure meter midpoints from the MySQL database instead:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;cmd&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;SELECT emmnwob, mnvel, errvel FROM exposuremeter e &amp;quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;cmd&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;INNER JOIN velocities v ON v.observation_id = e.observation_id &amp;quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;cmd&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;INNER JOIN observations o ON o.observation_id = e.observation_id &amp;quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;cmd&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;WHERE object=22049 AND tag=&amp;#39;a&amp;#39; AND mnvel IS NOT NULL&amp;quot;&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;engine&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ccdb&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;connectChironDB&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;eerv&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_sql_query&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cmd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;engine&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;And converted the exposure meter midpoints to Julian Dates using
the &lt;code&gt;pandas&lt;/code&gt; &lt;code&gt;DatetimeIndex&lt;/code&gt; and &lt;code&gt;to_julian_date()&lt;/code&gt; methods:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;emmnwobjds&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DatetimeIndex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eerv&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;emmnwob&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;eerv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;emmnwobjd&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;emmnwobjds&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_julian_date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The next step was to restore the MOST data from file and downsample by taking a
running mean. Downsampling reduced the noise and allowed the photometry to
be combined with the RV data without completely dominating the solution.
Both restoring the data and downsampling were accomplished in
pandas with a little help from the &lt;code&gt;Time&lt;/code&gt; method in &lt;code&gt;astropy&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;astropy.time&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Time&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#restore data&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;eeph&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;epsEriMost.txt&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sep&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;\s+&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;skipinitialspace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#create JD astropy Time object for easy conversion to ISO format:&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;MostJds&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eeph&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MJD&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;2451545.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;jd&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#now store as DatetimeIndex&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;eeph&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;ObsDT&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DatetimeIndex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MostJds&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;#next create a one column series of flux values with the observation&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#time as the index:&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;eemr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Series&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eeph&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;flux&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eeph&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;ObsDT&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;mhc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;Mean&amp;#39;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;downsampledtimes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eemr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;resample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;480min&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;how&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mhc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_julian_date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;downsampledflux&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eemr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;resample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;480min&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;how&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mhc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Since the MOST data have reported homoscedastic errors (a rarity in astronomy)
this worked out. Otherwise, we’d need to take a weighted mean.&lt;/p&gt;

&lt;h4 id=&quot;the-maximum-likelihood-method&quot;&gt;The Maximum Likelihood Method&lt;/h4&gt;

&lt;p&gt;We would like to fit the spectroscopic and photometric data simultaneously
to get a self-consistent model describing the star. For a first step in doing
this, I went with a quick maximum likelihood approach. The log likehood function
for the problem is:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;\[
\ln{p(v, \phi|t, \sigma, t&#39;, \sigma&#39;, \Theta)} = - \frac{1}{2} \sum_{n}\left[ \frac{(v_{n} - f(t_{n}| \Theta))^{2}}{\sigma_{n}^2} + \ln{(2 \pi \sigma_{n}^{2})}\right]
- \frac{1}{2} \sum_{m}\left[ \frac{(\phi_{m} - f&#39;(t&#39;_{m}| \Theta))^{2}}{\sigma_{m}^{&#39;2}} + \ln{(2 \pi \sigma_{m}^{&#39;2})}\right]
\]&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;v_{n}&lt;/script&gt; is the radial velocity measurement for the &lt;script type=&quot;math/tex&quot;&gt;n^{th}&lt;/script&gt; observation taken at time &lt;script type=&quot;math/tex&quot;&gt;t_{n}&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;\sigma_{n}&lt;/script&gt; is the single measurement uncertainty, and &lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt; is the radial velocity spot model given our hyperparamers, &lt;script type=&quot;math/tex&quot;&gt;\Theta&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;\phi_{m}&lt;/script&gt; is the flux of the &lt;script type=&quot;math/tex&quot;&gt;m^{th}&lt;/script&gt; photometric observation happening at time &lt;script type=&quot;math/tex&quot;&gt;t&#39;&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;f&#39;&lt;/script&gt; is the photometric spot model given our same hyperparameters, &lt;script type=&quot;math/tex&quot;&gt;\Theta&lt;/script&gt;, and &lt;script type=&quot;math/tex&quot;&gt;\sigma_{m}^{&#39;}&lt;/script&gt; is the photometric uncertainty of the &lt;script type=&quot;math/tex&quot;&gt;m^{th}&lt;/script&gt; observation. The hyperparameters here are&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;the latitude of spot 1&lt;/li&gt;
  &lt;li&gt;the phase of spot 1&lt;/li&gt;
  &lt;li&gt;the fractional area of spot 1&lt;/li&gt;
  &lt;li&gt;the latitude of spot 2&lt;/li&gt;
  &lt;li&gt;the phase of spot 2&lt;/li&gt;
  &lt;li&gt;the fractional area of spot 2&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This was then driven by minimizing the negative of the log likelihood:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;c&quot;&gt;#use the scipy optimize method:&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scipy.optimize&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;op&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;nll&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lnlike&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;op&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;minimize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nll&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;theta_init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;verr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ferr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                     &lt;span class=&quot;n&quot;&gt;method&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;Powell&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;For a first pass we decided to include two spots. No spot growth or decay.
No differential rotation. Just something quick and dirty, but it was clear
at least two spots were needed. Below is an animation showing the result.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Show_ObsAnim12medPause.gif&quot; alt=&quot;Spot Modeling Photometry and Spectroscopy Simultaneously&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Tue, 10 Feb 2015 13:35:53 -0500</pubDate>
        <link>http://mattgiguere.github.io/2015/02/10/spot-modeling.html</link>
        <guid isPermaLink="true">http://mattgiguere.github.io/2015/02/10/spot-modeling.html</guid>
        
        <category>python,</category>
        
        <category>imagemagick,</category>
        
        <category>simulation,</category>
        
        <category>animation,</category>
        
        <category>pandas</category>
        
        
      </item>
    
      <item>
        <title>Barycentric Correction Results</title>
        <description>&lt;p&gt;I spent some time this weekend looking more into the barycentric correction.
I couldn’t figure out why the barycentric corrections from barycorr were so
much worse than from the old barycentric correction code. It turned out it
was because there was a bug with the CF structures — the modified julian
dates in the CF structures were stored as doubles, but somewhere in the
reduction pipeline they are treated as FLOATs, which only have precision
to about the minute level. This corresponds to introducing an error at
about the 2 m/s level. &lt;/p&gt;
</description>
        <pubDate>Sun, 08 Feb 2015 17:13:45 -0500</pubDate>
        <link>http://mattgiguere.github.io/2015/02/08/barycenter-results.html</link>
        <guid isPermaLink="true">http://mattgiguere.github.io/2015/02/08/barycenter-results.html</guid>
        
        <category>python,</category>
        
        <category>mpi4py,</category>
        
        <category>mcmc,</category>
        
        <category>osx,</category>
        
        <category>emcee,</category>
        
        <category>barycentric</category>
        
        <category>correction</category>
        
        
      </item>
    
      <item>
        <title>The CHIRON Barycentric Correction</title>
        <description>&lt;p&gt;When using the radial velocity method to search for planets orbiting
nearby stars, the dominant signal is always due to the Earth’s motion
about the barycenter of the solar system. Our annual orbit induces
a signal of 30,000 m/s. Furthermore, as the observatory rotates towards
the star, the Earth’s rotation can induce a maximumradial velocity of 400 m/s.
If we didn’t correct for these two effects, we would find all sorts of celestial
bodies with annual and daily orbits. But to find low mass planets, there are
all sorts of other motions and effects that need to be taken into account. For
example, if we didn’t account for the presence of Jupiter, we would see a 12 m/s
signal with a period of approximately 12 years. For each spectroscopic observation
we take, we calculate a precise photon-weighted midpoint of the observation, and
then calculate a barycentric correction to subtract from the Doppler measurement.
This barycentric correction takes into account the relative motions of all the
planets and many minor bodies in the Solar System, the position of the observatory
on Earth, leap seconds due to events such as storms and earth quakes on Earth that
speed up or slow down the Earth’s rotation, etc. For a great description of all that
goes into the barycentric correction, see &lt;a href=&quot;http://arxiv.org/abs/1409.4774&quot;&gt;Barycentric Corrections at 1 cm/s for precise Doppler velocities&lt;/a&gt; by Wright &amp;amp; Eastman (2014).&lt;/p&gt;

&lt;p&gt;The other day I noticed a rather interesting correlation between the radial velocity
measurements and the barycentric correction. It can be seen in the following plot, which
shows the RV Measurements as a function of the Barycentric Correction.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Show_RvVsBary2Years.png&quot; alt=&quot;RV Measurements as a Function of Barycentric Correction&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In red are Doppler measurements based on CHIRON observations of Tau Ceti in 2014, and in blue are
the same, but based on 2012 data. While the correlation is not perfect, it’s quite clear in
a few regions (e.g, &amp;lt; -20,000 m/s, and between -8,000 m/s and 0 m/s). This can be
seen a little more clearly by applying a running mean to the data, which
can be seen at the solid lines in the following figure.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Show_RvVsBary2YearsBoxcar.png&quot; alt=&quot;Same as above, but with a running mean&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This signal is not really periodic, so it’s most likely not due to a planet in a perfect harmonic
with the Earth’s orbit, and I also wouldn’t expect it to be due to an issue with the barycentric
correction for the same reason. However, we want to make sure we have the best barycentric
correction possible so that we can find genuine low mass planets and not harmonics of a
poor treatment of the motions of celestial bodies in our Solar System. A simple first step was
to replace our current barycentric correction code with the improved code by the above mentioned
&lt;a href=&quot;http://adsabs.harvard.edu/abs/2014PASP..126..838W&quot;&gt;Wright &amp;amp; Eastman (2014)&lt;/a&gt;. So I downloaded
&lt;a href=&quot;http://astroutils.astronomy.ohio-state.edu/exofast/&quot;&gt;their code&lt;/a&gt;, and all the dependencies,
setup Launch Daemon scripts to check for daily updates for leap seconds and so forth, and
recalculated the barycentric corrections for all of our velocity measurements. The result
was an RMS for the Tau Ceti RV time series that was 30 cm/s greater than the RMS from the previous
code.&lt;/p&gt;

&lt;p&gt;I then started looking into everything that could be wrong. I double-checked that the coordinates
I was using were the most accurate. For Tau Ceti this required checking the RA, dec, proper motions,
and parallax were all from the
&lt;a href=&quot;https://heasarc.gsfc.nasa.gov/W3Browse/all/hipnewcat.html&quot;&gt;&lt;em&gt;Hipparcos&lt;/em&gt; New Astrometric Catalog&lt;/a&gt;
(&lt;a href=&quot;http://adsabs.harvard.edu/cgi-bin/bib_query?2007A&amp;amp;A...474..653V&quot;&gt;van Leeuwen (2007)&lt;/a&gt;). The whole
catalog can be found online on the Vizier site. The data for Tau Ceti in particular can be found
&lt;a href=&quot;http://vizier.u-strasbg.fr/viz-bin/VizieR-5?-ref=VIZ54d3a7714f13&amp;amp;-out.add=.&amp;amp;-source=I/311/hip2&amp;amp;recno=8087&quot;&gt;here&lt;/a&gt;.
For CTIO, the most precise coordinates for the 1.5 m were measured by
&lt;a href=&quot;http://arxiv.org/abs/1210.1616&quot;&gt;Mamajek (2012)&lt;/a&gt;. I was indeed already using the most up to date
coordinates.&lt;/p&gt;

&lt;p&gt;I then decided maybe we can do better than these measurements. We have this great time series of
precise RV measurements. Can you we use those measurements to infer a more accurate position of
the observatory here on Earth and a more accurate position and relative motions for Tau Ceti? I
thought it’d be worth a shot, so I setup &lt;a href=&quot;http://dan.iel.fm/emcee/current/&quot;&gt;emcee&lt;/a&gt; on several
machines in our group cluster, got MPI running on all the machines, and thought I’d try calculating
more accurate hyperparameters through sampling the posterior PDF.&lt;/p&gt;

&lt;p&gt;For priors for the observatory position I used Gaussians that were centered on the Mamjek values
and had a standard deviations that were a factor of a few larger than the standard deviation
of the previously measured values. These priors are shown below, where the vertical blue lines
show previously published results, and the red lines show the resulting priors.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Show_ObservatoryPriors.png&quot; alt=&quot;CTIO 1.5 m Observatory Coordinate Priors&quot; /&gt;&lt;/p&gt;

&lt;p&gt;For the priors for the coordinates and motions of Tau Ceti I again used Gaussians centered on
the &lt;em&gt;Hipparcos&lt;/em&gt; data with standard deviations a few times those of their reported uncertainties.
These can be seen below, where the values and uncertainties from the intial reduction are shown
in blue, and values and uncertainties from the new reduction mentioned above are shown in yellow,
and the priors used are shown in red.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Show_TauCetiCoordsPriors.png&quot; alt=&quot;CTIO 1.5 m Observatory Coordinate Priors&quot; /&gt;&lt;/p&gt;

&lt;p&gt;After some tweaking, the 100 walkers had a nice spread in their intial values to properly probe
the parameter space within a reasonable number of steps. The resulting chains for each parameter
as a function of step number can be seen below.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Show_Chains.png&quot; alt=&quot;MCMC Chains&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I then said the burn-in period completed in about 200 steps, cut those out, and below are the
resulting distributions from sampling the posterior.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Show_TriCornerCoords.png&quot; alt=&quot;Triangle Plot Showing PDFs&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The median values for each parameter were then fed into &lt;code&gt;barycorr&lt;/code&gt;. This reduced the RMS, but
still not below the value from the old barycorr.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Method&lt;/th&gt;
      &lt;th&gt;RMS&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Old Barycode&lt;/td&gt;
      &lt;td&gt;2.178 m/s&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Barycorr J2000- Hip &amp;amp; Mam vals&lt;/td&gt;
      &lt;td&gt;2.722 m/s&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Barycorr /hip - Hip &amp;amp; Mam vals&lt;/td&gt;
      &lt;td&gt;2.474 m/s&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Barycorr /hip - MCMC vals&lt;/td&gt;
      &lt;td&gt;2.467 m/s&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;I then looked into whether or not any structure existed between the old barycentric correction
and the new. The time series of the (“Old Barycode” - “Barycorr with Mamajek (2012) and van Leeuwen (2007) (1991.25 Epoch))
 residuals is shown below.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Show_BarycentricDifference.png&quot; alt=&quot;Residual Time Series of Old Barycode - Barycorr w. Mamajek and van Leeuwen vals (1991.25 Epoch)&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I was a little surprised to see the lack of structure in the residuals. I was expecting something
with maybe an annual, semi-annual, or at least periodic signal. Looking at the distribution of
the residuals shows nothing strange — they appear roughly normally distributed about some offset.
Since we’re only concerned with differential RVs, the offset isn’t a big deal. I know we’ve seen
this before.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Show_OldBC-BarycorrHipMamajekVanLeeuwenDist.png&quot; alt=&quot; Distribution of Old Barycode - Barycorr w. Mamajek and van Leeuwen vals (1991.25 Epoch)&quot; /&gt;&lt;/p&gt;

&lt;p&gt;And looking at a periodogram of the time series shows nothing significant. Below is a plot showing the
periodogoram of the same data set: Old barycode - Barycorr with Mamajek (2012) CTIO 1.5 m, van Leeuwen (2007),
and 1991.25 Epoch. The superimposed horizontal lines are the 95% and 99% confidence levels based on a Boostrap
MC analysis. These show that there is no significant power at any period between 0.1 and 400 days.
The highest peak is at a period of 117.79 days, and the second highest peak is at period of 171.43 days.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Show_OldBC-BarycorrHipMamajekVanLeeuwenPerg.png&quot; alt=&quot;Periodogram of Old Barycode - Barycorr w. Mamajek and van Leeuwen vals (Hip Epoch)&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Thu, 05 Feb 2015 07:56:12 -0500</pubDate>
        <link>http://mattgiguere.github.io/2015/02/05/barycentric-correction.html</link>
        <guid isPermaLink="true">http://mattgiguere.github.io/2015/02/05/barycentric-correction.html</guid>
        
        <category>python,</category>
        
        <category>mpi4py,</category>
        
        <category>mcmc,</category>
        
        <category>osx,</category>
        
        <category>emcee,</category>
        
        <category>barycentric</category>
        
        <category>correction</category>
        
        
      </item>
    
      <item>
        <title>Setting up mpi4py</title>
        <description>&lt;p&gt;Today I’ve been trying to get &lt;code&gt;emcee&lt;/code&gt; up and running and to use it with MPI. There were a number of obstacles that I needed to overcome to get MPI working on multiple machines.&lt;/p&gt;

&lt;p&gt;I have an anaconda installation of python, and mpi4py is one of the packages they support (more below), so I installed mpi4py using the following command:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sh&quot; data-lang=&quot;sh&quot;&gt;conda install mpi4py&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;But when I tried running it I got the following error:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sh&quot; data-lang=&quot;sh&quot;&gt;/opt/anaconda1anaconda2anaconda3/share/openmpi/help-opal-runtime.txt&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Fortunately for me, &lt;a href=&quot;https://groups.google.com/a/continuum.io/forum/#!topic/anaconda/7CsGQKNvcdQ&quot;&gt;someone else encountered a similar error&lt;/a&gt;. Until anaconda fixes their bug, an inelegant hack is to make a symbolic link pointing from /opt/ana… to the correct path. I have anaconda python installed for all users, so instead of pointing the symbolic link to my home directory, I pointed it to the directory containing the anaconda python distribution, the Applications directory:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sh&quot; data-lang=&quot;sh&quot;&gt;sudo ln -s /Applications/anaconda/ /opt/anaconda1anaconda2anaconda3&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;I did this on all 5 machines that I plan on testing MPI on. The next step is to create a hostfile containing the names or IP addresses of all hosts that will be used for computing. This is just a simple text file containing nothing more than the name of the host and the number of slots, or threads, to run on it at any given time:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sh&quot; data-lang=&quot;sh&quot;&gt;host1.example.edu &lt;span class=&quot;nv&quot;&gt;slots&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;12
host2.example.edu &lt;span class=&quot;nv&quot;&gt;slots&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;8&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The example tests in the &lt;a href=&quot;http://mpi4py.scipy.org/docs/usrman/install.html&quot;&gt;mpi4py documentation&lt;/a&gt; failed for me, but @jbornschein put together a nice &lt;a href=&quot;https://github.com/jbornschein/mpi4py-examples&quot;&gt;github repository with some example code&lt;/a&gt;. I ran the 01-helloworld example, specifying the hosts I wanted to distribute the jobs to:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sh&quot; data-lang=&quot;sh&quot;&gt;&lt;span class=&quot;nb&quot;&gt;cd &lt;/span&gt;projects/mpi4pyexamples
mpirun --hostfile myhostfile.txt ./01-helloworld&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;After a rather long delay in returning a result, an error was returned saying it could connect on the default port. That makes sense since we use non-default ports for our machines. After some searching, it doesn’t seem like there’s any way to specify the port in the hostfile, instead I used an ssh config file. I’m using Mac OS X 10.10, and setting a config file up was quite quick and easy to do:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sh&quot; data-lang=&quot;sh&quot;&gt;emacs ~/.ssh/config&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;and for contents add&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sh&quot; data-lang=&quot;sh&quot;&gt;Host host1.example.edu
   Hostname host1.example.edu
   Port 2400

Host host2.example.edu
   Hostname host2.example.edu
   Port 2400&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;After adding the hosts and ports to the &lt;code&gt;config&lt;/code&gt; file, I didn’t need to restart, or open a new terminal window or anything else that might be expected. Reissuing the same command in the same terminal window returned an immediate result:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sh&quot; data-lang=&quot;sh&quot;&gt;∞ mpirun --hostfile myhostfile ./01-hello-world
Hello! I&lt;span class=&quot;s1&quot;&gt;&amp;#39;m rank 1 from 8 running in total...&lt;/span&gt;
&lt;span class=&quot;s1&quot;&gt;Hello! I&amp;#39;&lt;/span&gt;m rank &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt; from &lt;span class=&quot;m&quot;&gt;8&lt;/span&gt; running in total...
Hello! I&lt;span class=&quot;s1&quot;&gt;&amp;#39;m rank 0 from 8 running in total...&lt;/span&gt;
&lt;span class=&quot;s1&quot;&gt;Hello! I&amp;#39;&lt;/span&gt;m rank &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt; from &lt;span class=&quot;m&quot;&gt;8&lt;/span&gt; running in total...
Hello! I&lt;span class=&quot;s1&quot;&gt;&amp;#39;m rank 7 from 8 running in total...&lt;/span&gt;
&lt;span class=&quot;s1&quot;&gt;Hello! I&amp;#39;&lt;/span&gt;m rank &lt;span class=&quot;m&quot;&gt;4&lt;/span&gt; from &lt;span class=&quot;m&quot;&gt;8&lt;/span&gt; running in total...
Hello! I&lt;span class=&quot;s1&quot;&gt;&amp;#39;m rank 5 from 8 running in total...&lt;/span&gt;
&lt;span class=&quot;s1&quot;&gt;Hello! I&amp;#39;&lt;/span&gt;m rank &lt;span class=&quot;m&quot;&gt;6&lt;/span&gt; from &lt;span class=&quot;m&quot;&gt;8&lt;/span&gt; running in total...
^Cmpirun: killing job...&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;However, as you can see things didn’t end very well. I had to kill the job, otherwise I end up with a strange error:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sh&quot; data-lang=&quot;sh&quot;&gt;∞ mpirun --hostfile hostfile ./01-hello-world
Hello! I&lt;span class=&quot;s1&quot;&gt;&amp;#39;m rank 0 from 8 running in total...&lt;/span&gt;
&lt;span class=&quot;s1&quot;&gt;Hello! I&amp;#39;&lt;/span&gt;m rank &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt; from &lt;span class=&quot;m&quot;&gt;8&lt;/span&gt; running in total...
Hello! I&lt;span class=&quot;s1&quot;&gt;&amp;#39;m rank 1 from 8 running in total...&lt;/span&gt;
&lt;span class=&quot;s1&quot;&gt;Hello! I&amp;#39;&lt;/span&gt;m rank &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt; from &lt;span class=&quot;m&quot;&gt;8&lt;/span&gt; running in total...
Hello! I&lt;span class=&quot;s1&quot;&gt;&amp;#39;m rank 4 from 8 running in total...&lt;/span&gt;
&lt;span class=&quot;s1&quot;&gt;Hello! I&amp;#39;&lt;/span&gt;m rank &lt;span class=&quot;m&quot;&gt;5&lt;/span&gt; from &lt;span class=&quot;m&quot;&gt;8&lt;/span&gt; running in total...
Hello! I&lt;span class=&quot;s1&quot;&gt;&amp;#39;m rank 6 from 8 running in total...&lt;/span&gt;
&lt;span class=&quot;s1&quot;&gt;Hello! I&amp;#39;&lt;/span&gt;m rank &lt;span class=&quot;m&quot;&gt;7&lt;/span&gt; from &lt;span class=&quot;m&quot;&gt;8&lt;/span&gt; running in total...
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;host2.example.edu&lt;span class=&quot;o&quot;&gt;][[&lt;/span&gt;7061,1&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;,4&lt;span class=&quot;o&quot;&gt;][&lt;/span&gt;btl_tcp_endpoint.c:638:mca_btl_tcp_endpoint_complete_connect&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; connect&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; to 128.5.5.6 failed: Operation timed out &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;60&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;host2.example.edu&lt;span class=&quot;o&quot;&gt;][[&lt;/span&gt;7061,1&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;,5&lt;span class=&quot;o&quot;&gt;][&lt;/span&gt;btl_tcp_endpoint.c:638:mca_btl_tcp_endpoint_complete_connect&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; connect&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; to 128.5.5.6 failed: Operation timed out &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;60&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;host2.example.edu&lt;span class=&quot;o&quot;&gt;][[&lt;/span&gt;7061,1&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;,6&lt;span class=&quot;o&quot;&gt;][&lt;/span&gt;btl_tcp_endpoint.c:638:mca_btl_tcp_endpoint_complete_connect&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; connect&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; to 128.5.5.6 failed: Operation timed out &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;60&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;host2.example.edu&lt;span class=&quot;o&quot;&gt;][[&lt;/span&gt;7061,1&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;,7&lt;span class=&quot;o&quot;&gt;][&lt;/span&gt;btl_tcp_endpoint.c:638:mca_btl_tcp_endpoint_complete_connect&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; connect&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; to 128.5.5.6 failed: Operation timed out &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;60&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;host1.example.edu&lt;span class=&quot;o&quot;&gt;][[&lt;/span&gt;7061,1&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;,0&lt;span class=&quot;o&quot;&gt;][&lt;/span&gt;btl_tcp_endpoint.c:638:mca_btl_tcp_endpoint_complete_connect&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; connect&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; to 128.5.5.5 failed: Operation timed out &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;60&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;host1.example.edu&lt;span class=&quot;o&quot;&gt;][[&lt;/span&gt;7061,1&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;,1&lt;span class=&quot;o&quot;&gt;][&lt;/span&gt;btl_tcp_endpoint.c:638:mca_btl_tcp_endpoint_complete_connect&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; connect&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; to 128.5.5.5 failed: Operation timed out &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;60&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;host1.example.edu&lt;span class=&quot;o&quot;&gt;][[&lt;/span&gt;7061,1&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;,2&lt;span class=&quot;o&quot;&gt;][&lt;/span&gt;btl_tcp_endpoint.c:638:mca_btl_tcp_endpoint_complete_connect&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; connect&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; to 128.5.5.5 failed: Operation timed out &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;60&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;host1.example.edu&lt;span class=&quot;o&quot;&gt;][[&lt;/span&gt;7061,1&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;,3&lt;span class=&quot;o&quot;&gt;][&lt;/span&gt;btl_tcp_endpoint.c:638:mca_btl_tcp_endpoint_complete_connect&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; connect&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; to 128.5.5.5 failed: Operation timed out &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;60&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;I downloaded the &lt;a href=&quot;https://bitbucket.org/mpi4py/mpi4py/downloads&quot;&gt;source code&lt;/a&gt; for mpi4py, changed directories into the downloaded directory and tried running their tests:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sh&quot; data-lang=&quot;sh&quot;&gt;mpiexec --hostfile hostfile python &lt;span class=&quot;nb&quot;&gt;test&lt;/span&gt;/runtests.py&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Running &lt;code&gt;runtests.py&lt;/code&gt; when the &lt;code&gt;hostfile&lt;/code&gt; contains only &lt;code&gt;host1.example.edu&lt;/code&gt; or &lt;code&gt;host2.example.edu&lt;/code&gt; works fine. However, when I include both hosts I end up with the same error as the &lt;code&gt;helloworld.py&lt;/code&gt; example. This error doesn’t crop up with the &lt;code&gt;mpi4py&lt;/code&gt; &lt;code&gt;helloworld&lt;/code&gt; example, just the &lt;code&gt;mpi4py-examples&lt;/code&gt; &lt;code&gt;helloworld&lt;/code&gt;. The difference between the failed and successful versions being that the version that fails waits for all jobs to finish up at the end through &lt;code&gt;comm.Barrier()&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://stackoverflow.com/questions/15072563/running-mpi-on-two-hosts&quot;&gt;This article&lt;/a&gt;, which discusses the communication was helpful — it appears the two computers, host1 and host2, can communicate with the machine I am running the commands from, but they cannot communicate with eachother.&lt;/p&gt;

&lt;p&gt;I disabled the firewall through System Preferences -&amp;gt; Security &amp;amp; Privacy. This worked for the &lt;code&gt;helloworld.py&lt;/code&gt; example, but not for &lt;code&gt;tests/runtests.py&lt;/code&gt;. I should also mention that &lt;code&gt;host1&lt;/code&gt; has 12 cores and &lt;code&gt;host2&lt;/code&gt; has 8 cores. While testing out my hostfile I had reduced the number of “slots” on each to 4 and it worked. When I increased the number of slots on either host above 4, the connection failed error message reappeared when running &lt;code&gt;helloworld.py&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;It looks like part of the problem may be that &lt;code&gt;host1&lt;/code&gt; and &lt;code&gt;host2&lt;/code&gt; are using different SSH ports, and therefore cannot communicate between each other. I switched to using two host machines that are using the same ports for SSH, and both &lt;code&gt;helloworld.py&lt;/code&gt; and &lt;code&gt;runtests.py&lt;/code&gt; finished up successfully.&lt;/p&gt;

&lt;p&gt;However, adding a third machine is now causing issues…&lt;/p&gt;

&lt;p&gt;This turned out to be that the firewall was still on despite turning it off through the GUI in system preferences. Simply turning the firewall off through the System Preferences GUI worked on 2 of the 3 machines, so I’m not sure why it got hung up on the third. If you’re having similar problems, try taking a look at either “All Messages” or “secure.log” in the console (or /var/log/secure.log) on the mac host. If you see lines stating that the Firewall refused connection, this is your problem too. Simply restarting the system did the trick. I’ve now added several more machines and have executed &lt;code&gt;helloworld.py&lt;/code&gt; and &lt;code&gt;tests/runtests.py&lt;/code&gt; successfully on 96 cores!&lt;/p&gt;
</description>
        <pubDate>Tue, 27 Jan 2015 13:25:09 -0500</pubDate>
        <link>http://mattgiguere.github.io/2015/01/27/setting-up-mpi4py.html</link>
        <guid isPermaLink="true">http://mattgiguere.github.io/2015/01/27/setting-up-mpi4py.html</guid>
        
        <category>python,</category>
        
        <category>mpi4py,</category>
        
        <category>mcmc,</category>
        
        <category>osx,</category>
        
        <category>anaconda</category>
        
        
      </item>
    
  </channel>
</rss>
